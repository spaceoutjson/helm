apiVersion: v1
entries:
  lingo:
  - apiVersion: v2
    appVersion: v0.0.7
    created: "2024-02-21T07:41:55.593105519Z"
    description: A Helm chart for Lingo, the K8s LLM proxy and autoscaler
    digest: a46c3e9772ee37101e6c99073df7755ab4485bc28e8bf654a30f620f99287f65
    home: https://github.com/substratusai/lingo
    keywords:
    - llm
    - proxy
    - autoscaler
    - openai
    maintainers:
    - name: Sam Stoelinga
      url: https://www.linkedin.com/in/samstoelinga/
    name: lingo
    type: application
    urls:
    - https://github.com/spaceoutjson/helm/releases/download/lingo-0.1.8/lingo-0.1.8.tgz
    version: 0.1.8
  vllm:
  - apiVersion: v2
    appVersion: v0.3.1
    created: "2024-02-21T11:32:30.896527809Z"
    description: 'A Helm chart for deploying vLLM. vLLM is a fast and easy-to-use
      library for LLM inference and serving. '
    digest: 568d195b251b126a0cc29d78721f6905f7e49d79c107c3e2cfd5ee7c573d0e06
    name: vllm
    type: application
    urls:
    - https://github.com/spaceoutjson/helm/releases/download/vllm-0.3.1/vllm-0.3.1.tgz
    version: 0.3.1
  - apiVersion: v2
    appVersion: v0.3.1
    created: "2024-02-24T00:32:14.688331216Z"
    description: 'A Helm chart for deploying vLLM. vLLM is a fast and easy-to-use
      library for LLM inference and serving. '
    digest: 87036fd2c75fba43c08fd229a35370ad971cc3dc4352717c81c1cc7aa9c7e730
    name: vllm
    type: application
    urls:
    - https://github.com/spaceoutjson/helm/releases/download/vllm-0.3.0/vllm-0.3.0.tgz
    version: 0.3.0
  - apiVersion: v2
    appVersion: v0.3.1
    created: "2024-02-24T03:40:05.772165974Z"
    description: 'A Helm chart for deploying vLLM. vLLM is a fast and easy-to-use
      library for LLM inference and serving. '
    digest: 243544e744fcfaee0aa34cace135961c4e35e0f731054e45d5472d35c49ad3fd
    name: vllm
    type: application
    urls:
    - https://github.com/spaceoutjson/helm/releases/download/vllm-0.2.2/vllm-0.2.2.tgz
    version: 0.2.2
  - apiVersion: v2
    appVersion: v0.3.1
    created: "2024-02-24T03:04:13.505244664Z"
    description: 'A Helm chart for deploying vLLM. vLLM is a fast and easy-to-use
      library for LLM inference and serving. '
    digest: bbeec8ca24d98edfb8c18954e1b209b1bcfd545f4580958ac486b216f57d7c7f
    name: vllm
    type: application
    urls:
    - https://github.com/spaceoutjson/helm/releases/download/vllm-0.2.1/vllm-0.2.1.tgz
    version: 0.2.1
  - apiVersion: v2
    appVersion: v0.3.1
    created: "2024-02-24T02:35:30.788175336Z"
    description: 'A Helm chart for deploying vLLM. vLLM is a fast and easy-to-use
      library for LLM inference and serving. '
    digest: ba6f1d2afca1e1149857746cc769b803e897a7682d5c6bed6a5273ea739bfd7b
    name: vllm
    type: application
    urls:
    - https://github.com/spaceoutjson/helm/releases/download/vllm-0.2.0/vllm-0.2.0.tgz
    version: 0.2.0
generated: "2024-02-24T03:40:05.77219617Z"
